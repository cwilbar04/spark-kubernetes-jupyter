{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth activate-service-account --key-file=untitled.txt --project=spark-on-kubernetes-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud container clusters get-credentials spark-cluster --region=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cluster-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, BooleanType, ArrayType, LongType\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"kubernetes\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session and Load BigQuery jar file\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"kubernetes\") \\\n",
    "    .config(\"spark.master\",\"k8s://https://35.239.173.65:443\") \\\n",
    "    .config(\"spark.submit.deployMode\",\"cluster\") \\\n",
    "    .config(\"spark.executor.instances\",\"3\") \\\n",
    "    .config(\"spark.kubernetes.container.image\",\"gcr.io/spark-on-kubernetes-testing/spark-cluster-spark-base:latest\") \\\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",\"spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema of files to parse\n",
    "schema = StructType([ \n",
    "    StructField(\"asin\",StringType(),True), \n",
    "    StructField(\"image\",ArrayType(StringType()),True), \n",
    "    StructField(\"overall\",DoubleType(),True),\n",
    "    StructField(\"reviewText\",StringType(),True),\n",
    "    StructField(\"reviewTime\",StringType(),True),\n",
    "    StructField(\"reviewerID\",StringType(),True),\n",
    "    StructField(\"reviewerName\",StringType(),True),\n",
    "    StructField(\"summary\",StringType(),True),\n",
    "    StructField(\"unixReviewTime\",LongType(),True),\n",
    "    StructField(\"verified\",BooleanType(),True),\n",
    "    StructField(\"vote\",StringType(),True),\n",
    "    StructField(\"style\",ArrayType(StringType()),True)\n",
    "  ])\n",
    "\n",
    "# URL to scrape to get files to download\n",
    "url = \"https://nijianmo.github.io/amazon/index.html\"\n",
    "html = requests.get(url)\n",
    "\n",
    "if html.ok:\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')  \n",
    "\n",
    "output_final = []\n",
    "files = []\n",
    "links = soup.find_all('a',string='5-core')#.find('5-core')#.find_all('td', id='5-core')\n",
    "for link in links[0:1]:\n",
    "    url = link.get('href')\n",
    "    file = url.split('/')[-1]\n",
    "    print(url)\n",
    "    print(url.split('/')[-1])\n",
    "    spark.sparkContext.addFile(url)\n",
    "    files.append(file)\n",
    "    df = spark.read.json(\"file://\"+SparkFiles.get(file),schema)\n",
    "\n",
    "df.show(5)"
   ]
  }
 ]
}